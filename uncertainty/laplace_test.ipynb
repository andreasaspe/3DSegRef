{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf244515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting laplace-torch\n",
      "  Using cached laplace_torch-0.2.2.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting asdfghjkl==0.1a4 (from laplace-torch)\n",
      "  Using cached asdfghjkl-0.1a4-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting backpack-for-pytorch (from laplace-torch)\n",
      "  Using cached backpack_for_pytorch-1.7.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting curvlinops-for-pytorch>=2.0 (from laplace-torch)\n",
      "  Using cached curvlinops_for_pytorch-2.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from laplace-torch) (2.3.2)\n",
      "Collecting opt_einsum (from laplace-torch)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: torch>=2.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from laplace-torch) (2.8.0)\n",
      "Requirement already satisfied: torchmetrics in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from laplace-torch) (1.8.1)\n",
      "Requirement already satisfied: torchvision>=0.15 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from laplace-torch) (0.23.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.7.1 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (1.16.1)\n",
      "Collecting numpy (from laplace-torch)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.61.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (4.67.1)\n",
      "Requirement already satisfied: einops in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (0.8.1)\n",
      "Collecting einconv (from curvlinops-for-pytorch>=2.0->laplace-torch)\n",
      "  Using cached einconv-0.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting unfoldNd<1.0.0,>=0.2.0 (from backpack-for-pytorch->laplace-torch)\n",
      "  Downloading unfoldNd-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from unfoldNd<1.0.0,>=0.2.0->backpack-for-pytorch->laplace-torch) (25.0)\n",
      "Requirement already satisfied: filelock in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torch>=2.0->laplace-torch) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0->laplace-torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torchvision>=0.15->laplace-torch) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from jinja2->torch>=2.0->laplace-torch) (3.0.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /scratch/pjtka/NDSegUnc/lib/python3.13/site-packages (from torchmetrics->laplace-torch) (0.15.2)\n",
      "Using cached laplace_torch-0.2.2.2-py3-none-any.whl (77 kB)\n",
      "Using cached asdfghjkl-0.1a4-py3-none-any.whl (89 kB)\n",
      "Using cached curvlinops_for_pytorch-2.0.1-py3-none-any.whl (67 kB)\n",
      "Using cached backpack_for_pytorch-1.7.1-py3-none-any.whl (196 kB)\n",
      "Downloading unfoldNd-0.2.3-py3-none-any.whl (16 kB)\n",
      "Using cached einconv-0.1.0-py3-none-any.whl (27 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-linux_x86_64.whl size=8811266 sha256=f125c9a81afbb935e89590300c3293ab0efebfe29d1c2f3ea801adff22deea7e\n",
      "  Stored in directory: /home/pjtka/.cache/pip/wheels/8b/2d/9f/b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "Successfully built numpy\n",
      "Installing collected packages: opt_einsum, numpy, unfoldNd, einconv, asdfghjkl, backpack-for-pytorch, curvlinops-for-pytorch, laplace-torch\n",
      "\u001b[2K  Attempting uninstall: numpy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/8\u001b[0m [opt_einsum]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.2\u001b[0m \u001b[32m0/8\u001b[0m [opt_einsum]\n",
      "\u001b[2K    Uninstalling numpy-2.3.2:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.2━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [laplace-torch]0m [laplace-torch]-pytorch]\n",
      "\u001b[1A\u001b[2KSuccessfully installed asdfghjkl-0.1a4 backpack-for-pytorch-1.7.1 curvlinops-for-pytorch-2.0.1 einconv-0.1.0 laplace-torch-0.2.2.2 numpy-1.26.4 opt_einsum-3.4.0 unfoldNd-0.2.3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f97fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from trainer import Trainer\n",
    "import laplace\n",
    "\n",
    "model_kwargs = {\n",
    "    'checkpoint_path': '/scratch/pjtka/nnUNet/nnUNet_results/Dataset004_TotalSegmentatorPancreas/nnUNetTrainerNoMirroring__nnUNetResEncUNetLPlans__3d_fullres/fold_0/checkpoint_best.pth',\n",
    "    'loss_kwargs': {\n",
    "                    'lambda_ce':1.0,\n",
    "                    'lambda_dice':1.0,\n",
    "                    'lambda_nll': 1.0,\n",
    "                    'lambda_kl': 1e-4\n",
    "                },\n",
    "    'path_to_base': '/scratch/awias/data/nnUNet/info_dict_TotalSegmentatorPancreas.pkl',\n",
    "    'num_samples_train': 5,\n",
    "    'num_samples_inference': 30\n",
    "}\n",
    "\n",
    "training_kwargs = {\n",
    "    'num_epochs': 20,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'output_dir': '/scratch/pjtka/ndseg_output/laplace',\n",
    "    'num_iterations_per_epoch': 250,\n",
    "    'num_val_iterations': 5,\n",
    "    'loss_kwargs': {\n",
    "                    'lambda_ce':1.0,\n",
    "                    'lambda_dice':1.0,\n",
    "                    'lambda_nll': 1.0,\n",
    "                    'lambda_kl': 1e-4\n",
    "                },\n",
    "    \n",
    "    'eval_loader_data_path': '/scratch/pjtka/pancreas_validation',\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22fe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/pjtka/ndseg_output/laplace\n",
      "Loss initialized with ce: 1.0 dice: 1.0 kl: 0.0001\n",
      "Starting from checkpoint /scratch/pjtka/nnUNet/nnUNet_results/Dataset004_TotalSegmentatorPancreas/nnUNetTrainerNoMirroring__nnUNetResEncUNetLPlans__3d_fullres/fold_0/checkpoint_best.pth\n",
      "_IncompatibleKeys(missing_keys=['cov_basis_mat', 'decoder.diag_head.weight', 'decoder.diag_head.bias', 'decoder.cov_head.weight', 'decoder.cov_head.bias'], unexpected_keys=[])\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-09-03 20:31:59.001311: do_dummy_2d_data_aug: False\n",
      "2025-09-03 20:31:59.003988: Using splits from existing split file: /scratch/pjtka/nnUNet/nnUNet_preprocessed/Dataset004_TotalSegmentatorPancreas/splits_final.json\n",
      "2025-09-03 20:31:59.006169: The split file contains 5 splits.\n",
      "2025-09-03 20:31:59.007532: Desired fold for training: 0\n",
      "2025-09-03 20:31:59.008849: This split has 518 training and 130 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7 (results_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/threading.py\"\u001b[0m, line \u001b[35m1043\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/ipykernel/ipkernel.py\"\u001b[0m, line \u001b[35m766\u001b[0m, in \u001b[35mrun_closure\u001b[0m\n",
      "    \u001b[31m_threading_Thread_run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/threading.py\"\u001b[0m, line \u001b[35m994\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\"\u001b[0m, line \u001b[35m125\u001b[0m, in \u001b[35mresults_loop\u001b[0m\n",
      "    raise e\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\"\u001b[0m, line \u001b[35m108\u001b[0m, in \u001b[35mresults_loop\u001b[0m\n",
      "    item = in_queue.get()\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/queues.py\"\u001b[0m, line \u001b[35m120\u001b[0m, in \u001b[35mget\u001b[0m\n",
      "    return \u001b[31m_ForkingPickler.loads\u001b[0m\u001b[1;31m(res)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/torch/multiprocessing/reductions.py\"\u001b[0m, line \u001b[35m541\u001b[0m, in \u001b[35mrebuild_storage_fd\u001b[0m\n",
      "    fd = df.detach()\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/resource_sharer.py\"\u001b[0m, line \u001b[35m57\u001b[0m, in \u001b[35mdetach\u001b[0m\n",
      "    with \u001b[31m_resource_sharer.get_connection\u001b[0m\u001b[1;31m(self._id)\u001b[0m as conn:\n",
      "         \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/resource_sharer.py\"\u001b[0m, line \u001b[35m86\u001b[0m, in \u001b[35mget_connection\u001b[0m\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/connection.py\"\u001b[0m, line \u001b[35m525\u001b[0m, in \u001b[35mClient\u001b[0m\n",
      "    \u001b[31manswer_challenge\u001b[0m\u001b[1;31m(c, authkey)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/connection.py\"\u001b[0m, line \u001b[35m953\u001b[0m, in \u001b[35manswer_challenge\u001b[0m\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/connection.py\"\u001b[0m, line \u001b[35m216\u001b[0m, in \u001b[35mrecv_bytes\u001b[0m\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/connection.py\"\u001b[0m, line \u001b[35m430\u001b[0m, in \u001b[35m_recv_bytes\u001b[0m\n",
      "    buf = self._recv(4)\n",
      "  File \u001b[35m\"/scratch/pjtka/NDSegUnc/lib/python3.13/multiprocessing/connection.py\"\u001b[0m, line \u001b[35m395\u001b[0m, in \u001b[35m_recv\u001b[0m\n",
      "    chunk = read(handle, remaining)\n",
      "\u001b[1;35mConnectionResetError\u001b[0m: \u001b[35m[Errno 104] Connection reset by peer\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model_kwargs=model_kwargs, training_kwargs=training_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbfa199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpath = r'/scratch/pjtka/nnUNet/nnUNet_preprocessed/Dataset007_TotalSegmentatorAdrenal_gland_left'\n",
    "import os\n",
    "import json\n",
    "\n",
    "def open_json(bpath, name):\n",
    "    with open(os.path.join(bpath, name), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data \n",
    "\n",
    "dset = open_json(bpath,'dataset.json')\n",
    "finger = open_json(bpath,'dataset_fingerprint.json')\n",
    "splits = open_json(bpath,'splits_final.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6cfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(base_path, idx = 0):\n",
    "    splits = open_json(base_path, 'splits_final.json')\n",
    "    return splits[idx]['train'], splits[idx]['val']\n",
    "\n",
    "\n",
    "def get_identifiers(path):\n",
    "    case_identifiers = [i[:-5] for i in os.listdir(path) if i.endswith(\".b2nd\") and not i.endswith(\"_seg.b2nd\")]\n",
    "    return case_identifiers\n",
    "\n",
    "train_old, val_old = get_train_test_split(bpath)\n",
    "\n",
    "all_ids = get_identifiers(os.path.join(bpath, 'nnUNetPlans_3d_fullres'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e2e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e0d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = set(all_ids) - set(train_old) - set(val_old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2577564d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1006',\n",
       " '1013',\n",
       " '102',\n",
       " '1022',\n",
       " '1023',\n",
       " '1035',\n",
       " '1061',\n",
       " '108',\n",
       " '1089',\n",
       " '109',\n",
       " '111',\n",
       " '1135',\n",
       " '115',\n",
       " '1152',\n",
       " '1158',\n",
       " '1162',\n",
       " '1165',\n",
       " '117',\n",
       " '1174',\n",
       " '1183',\n",
       " '1189',\n",
       " '1196',\n",
       " '1199',\n",
       " '12',\n",
       " '120',\n",
       " '1207',\n",
       " '1209',\n",
       " '1212',\n",
       " '1216',\n",
       " '1221',\n",
       " '1228',\n",
       " '1233',\n",
       " '1238',\n",
       " '1248',\n",
       " '1255',\n",
       " '1271',\n",
       " '1276',\n",
       " '1288',\n",
       " '1294',\n",
       " '1298',\n",
       " '1304',\n",
       " '1330',\n",
       " '1331',\n",
       " '1334',\n",
       " '1340',\n",
       " '1348',\n",
       " '1349',\n",
       " '1361',\n",
       " '1370',\n",
       " '138',\n",
       " '1382',\n",
       " '1384',\n",
       " '1394',\n",
       " '1400',\n",
       " '1403',\n",
       " '1405',\n",
       " '1427',\n",
       " '151',\n",
       " '165',\n",
       " '171',\n",
       " '191',\n",
       " '194',\n",
       " '206',\n",
       " '223',\n",
       " '224',\n",
       " '227',\n",
       " '240',\n",
       " '247',\n",
       " '275',\n",
       " '299',\n",
       " '303',\n",
       " '305',\n",
       " '311',\n",
       " '315',\n",
       " '327',\n",
       " '338',\n",
       " '339',\n",
       " '342',\n",
       " '343',\n",
       " '345',\n",
       " '349',\n",
       " '362',\n",
       " '364',\n",
       " '383',\n",
       " '39',\n",
       " '398',\n",
       " '4',\n",
       " '40',\n",
       " '405',\n",
       " '413',\n",
       " '422',\n",
       " '423',\n",
       " '425',\n",
       " '428',\n",
       " '477',\n",
       " '485',\n",
       " '49',\n",
       " '498',\n",
       " '499',\n",
       " '50',\n",
       " '505',\n",
       " '509',\n",
       " '510',\n",
       " '519',\n",
       " '520',\n",
       " '523',\n",
       " '536',\n",
       " '543',\n",
       " '557',\n",
       " '565',\n",
       " '566',\n",
       " '579',\n",
       " '582',\n",
       " '592',\n",
       " '593',\n",
       " '6',\n",
       " '618',\n",
       " '620',\n",
       " '637',\n",
       " '644',\n",
       " '651',\n",
       " '667',\n",
       " '669',\n",
       " '679',\n",
       " '688',\n",
       " '690',\n",
       " '702',\n",
       " '714',\n",
       " '726',\n",
       " '728',\n",
       " '729',\n",
       " '737',\n",
       " '739',\n",
       " '740',\n",
       " '743',\n",
       " '749',\n",
       " '762',\n",
       " '764',\n",
       " '775',\n",
       " '78',\n",
       " '785',\n",
       " '790',\n",
       " '80',\n",
       " '810',\n",
       " '816',\n",
       " '842',\n",
       " '859',\n",
       " '866',\n",
       " '884',\n",
       " '885',\n",
       " '895',\n",
       " '896',\n",
       " '904',\n",
       " '908',\n",
       " '912',\n",
       " '923',\n",
       " '941',\n",
       " '946',\n",
       " '983',\n",
       " '986'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73ac9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = []\n",
    "for idx in range(5):\n",
    "    train, val = get_train_test_split(bpath, idx = idx)\n",
    "    splits.append({'test': list(test_ids),'train': train,'val': val})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78488133",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(bpath, 'splits_final.json'), 'w') as f:\n",
    "    json.dump(splits, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa3b99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,  x):\n",
    "        return x\n",
    "\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model \n",
    "        self.model.evaluate_with_samples = False\n",
    "        self.model.link_function = Identity()\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.decoder.seg_layers.requires_grad_(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output.mu.view(x.shape[1], -1)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    X = torch.cat([elem['data'] for elem in batch], dim = 0)\n",
    "    y = torch.cat([elem['target'][0].unsqueeze(0) for elem in batch], dim = 0)\n",
    "    return X, y \n",
    "\n",
    "\n",
    "data = torch.utils.data.Subset(trainer.eval_loader, indices = [1,2,3,4])\n",
    "model = WrappedModel(trainer.model)\n",
    "loader = DataLoader(data, collate_fn=collate_fn, batch_size=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb0aa9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter shape in network.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlaplace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Laplace \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m la = Laplace(model, \u001b[33m\"\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m\"\u001b[39m, subset_of_weights=\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m la.fit(loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/laplace/laplace.py:47\u001b[39m, in \u001b[36mLaplace\u001b[39m\u001b[34m(model, likelihood, subset_of_weights, hessian_structure, *args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m laplace_map = {\n\u001b[32m     42\u001b[39m     subclass._key: subclass\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subclass \u001b[38;5;129;01min\u001b[39;00m _all_subclasses(BaseLaplace)\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(subclass, \u001b[33m\"\u001b[39m\u001b[33m_key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m }\n\u001b[32m     46\u001b[39m laplace_class = laplace_map[(subset_of_weights, hessian_structure)]\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m laplace_class(model, likelihood, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/laplace/baselaplace.py:1684\u001b[39m, in \u001b[36mKronLaplace.__init__\u001b[39m\u001b[34m(self, model, likelihood, sigma_noise, prior_precision, prior_mean, temperature, enable_backprop, dict_key_x, dict_key_y, backend, damping, backend_kwargs, asdl_fisher_kwargs)\u001b[39m\n\u001b[32m   1682\u001b[39m \u001b[38;5;28mself\u001b[39m.damping: \u001b[38;5;28mbool\u001b[39m = damping\n\u001b[32m   1683\u001b[39m \u001b[38;5;28mself\u001b[39m.H_facs: Kron | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1684\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m   1685\u001b[39m     model,\n\u001b[32m   1686\u001b[39m     likelihood,\n\u001b[32m   1687\u001b[39m     sigma_noise,\n\u001b[32m   1688\u001b[39m     prior_precision,\n\u001b[32m   1689\u001b[39m     prior_mean,\n\u001b[32m   1690\u001b[39m     temperature,\n\u001b[32m   1691\u001b[39m     enable_backprop,\n\u001b[32m   1692\u001b[39m     dict_key_x,\n\u001b[32m   1693\u001b[39m     dict_key_y,\n\u001b[32m   1694\u001b[39m     backend,\n\u001b[32m   1695\u001b[39m     backend_kwargs,\n\u001b[32m   1696\u001b[39m     asdl_fisher_kwargs,\n\u001b[32m   1697\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/laplace/baselaplace.py:837\u001b[39m, in \u001b[36mParametricLaplace.__init__\u001b[39m\u001b[34m(self, model, likelihood, sigma_noise, prior_precision, prior_mean, temperature, enable_backprop, dict_key_x, dict_key_y, backend, backend_kwargs, asdl_fisher_kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    823\u001b[39m     model,\n\u001b[32m    824\u001b[39m     likelihood,\n\u001b[32m   (...)\u001b[39m\u001b[32m    834\u001b[39m     asdl_fisher_kwargs,\n\u001b[32m    835\u001b[39m )\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mH\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_H()\n\u001b[32m    838\u001b[39m     \u001b[38;5;66;03m# posterior mean/mode\u001b[39;00m\n\u001b[32m    839\u001b[39m     \u001b[38;5;28mself\u001b[39m.mean: \u001b[38;5;28mfloat\u001b[39m | torch.Tensor = \u001b[38;5;28mself\u001b[39m.prior_mean\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/laplace/baselaplace.py:1700\u001b[39m, in \u001b[36mKronLaplace._init_H\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1699\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_init_H\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     \u001b[38;5;28mself\u001b[39m.H: Kron | KronDecomposed | \u001b[38;5;28;01mNone\u001b[39;00m = Kron.init_from_model(\n\u001b[32m   1701\u001b[39m         \u001b[38;5;28mself\u001b[39m.params, \u001b[38;5;28mself\u001b[39m._device, \u001b[38;5;28mself\u001b[39m._dtype\n\u001b[32m   1702\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/pjtka/NDSegUnc/lib/python3.13/site-packages/laplace/utils/matrix.py:75\u001b[39m, in \u001b[36mKron.init_from_model\u001b[39m\u001b[34m(cls, model, device, dtype)\u001b[39m\n\u001b[32m     68\u001b[39m         kfacs.append(\n\u001b[32m     69\u001b[39m             [\n\u001b[32m     70\u001b[39m                 torch.zeros(P_in, P_in, device=device, dtype=dtype),\n\u001b[32m     71\u001b[39m                 torch.zeros(P_out, P_out, device=device, dtype=dtype),\n\u001b[32m     72\u001b[39m             ]\n\u001b[32m     73\u001b[39m         )\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid parameter shape in network.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(kfacs)\n",
      "\u001b[31mValueError\u001b[39m: Invalid parameter shape in network."
     ]
    }
   ],
   "source": [
    "from laplace import Laplace \n",
    "la = Laplace(model, \"classification\", subset_of_weights='all')\n",
    "la.fit(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1918e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<laplace.lllaplace.KronLLLaplace at 0x7fe6ec1667b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
